{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a13d23-d673-4cfe-8624-d863bcc76bb4",
   "metadata": {},
   "source": [
    "# Assignment 7 - Text Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6333b5-0fd1-4b33-8609-f65b93ffae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff3605c-75aa-4eb3-8eb2-57288861207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67dcef9-f35b-45d9-a403-4d5cc1da751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In the vast expanse of the digital realm, where information flows ceaselessly and boundaries blur between reality and virtuality, lies an intricate tapestry of interconnected nodes and networks. Within this labyrinthine landscape, individuals navigate the ever-shifting currents of data, seeking meaning amidst the chaos. From the bustling streets of social media platforms to the serene corridors of scholarly archives, voices echo and ideas converge in a symphony of diversity. Algorithms hum in the background, orchestrating the flow of content and shaping the digital discourse. Yet, amidst the noise, patterns emerge, revealing glimpses of insight and understanding.At the heart of this digital ecosystem lies the art and science of text analytics, a discipline dedicated to unraveling the mysteries hidden within the written word. Armed with computational tools and linguistic expertise, analysts embark on a journey of discovery, sifting through vast troves of textual data in search of nuggets of wisdom. Natural language processing algorithms parse sentences, extract entities, and discern sentiments, transforming raw text into structured knowledge. From sentiment analysis to topic modeling, text analytics unlocks a wealth of possibilities for understanding human behavior, informing decision-making, and driving innovation.In the realm of commerce, businesses harness the power of text analytics to glean insights from customer feedback, predict market trends, and personalize user experiences. Social scientists explore digital archives to study cultural shifts, linguistic evolution, and societal dynamics. Healthcare professionals employ text mining techniques to analyze medical records, detect patterns in patient symptoms, and enhance diagnostic accuracy. Meanwhile, policymakers turn to text analytics to monitor public opinion, track emerging issues, and inform governance strategies.As the digital landscape continues to evolve and expand, so too does the field of text analytics, pushing the boundaries of what is possible in the realm of language understanding. With each passing day, new technologies emerge, new methodologies evolve, and new frontiers beckon, inviting explorers to venture forth into the uncharted territories of the digital wilderness. And as they do, they carry with them the torch of knowledge, illuminating the path ahead and shedding light on the mysteries that lie beyond.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2508f249-9f97-4f64-b9c5-8a6709427a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9be6b9-4986-4740-b0eb-c446225505b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenization\n",
      "['In', 'the', 'vast', 'expanse', 'of', 'the', 'digital', 'realm', ',', 'where', 'information', 'flows', 'ceaselessly', 'and', 'boundaries', 'blur', 'between', 'reality', 'and', 'virtuality', ',', 'lies', 'an', 'intricate', 'tapestry', 'of', 'interconnected', 'nodes', 'and', 'networks', '.', 'Within', 'this', 'labyrinthine', 'landscape', ',', 'individuals', 'navigate', 'the', 'ever-shifting', 'currents', 'of', 'data', ',', 'seeking', 'meaning', 'amidst', 'the', 'chaos', '.', 'From', 'the', 'bustling', 'streets', 'of', 'social', 'media', 'platforms', 'to', 'the', 'serene', 'corridors', 'of', 'scholarly', 'archives', ',', 'voices', 'echo', 'and', 'ideas', 'converge', 'in', 'a', 'symphony', 'of', 'diversity', '.', 'Algorithms', 'hum', 'in', 'the', 'background', ',', 'orchestrating', 'the', 'flow', 'of', 'content', 'and', 'shaping', 'the', 'digital', 'discourse', '.', 'Yet', ',', 'amidst', 'the', 'noise', ',', 'patterns', 'emerge', ',', 'revealing', 'glimpses', 'of', 'insight', 'and', 'understanding.At', 'the', 'heart', 'of', 'this', 'digital', 'ecosystem', 'lies', 'the', 'art', 'and', 'science', 'of', 'text', 'analytics', ',', 'a', 'discipline', 'dedicated', 'to', 'unraveling', 'the', 'mysteries', 'hidden', 'within', 'the', 'written', 'word', '.', 'Armed', 'with', 'computational', 'tools', 'and', 'linguistic', 'expertise', ',', 'analysts', 'embark', 'on', 'a', 'journey', 'of', 'discovery', ',', 'sifting', 'through', 'vast', 'troves', 'of', 'textual', 'data', 'in', 'search', 'of', 'nuggets', 'of', 'wisdom', '.', 'Natural', 'language', 'processing', 'algorithms', 'parse', 'sentences', ',', 'extract', 'entities', ',', 'and', 'discern', 'sentiments', ',', 'transforming', 'raw', 'text', 'into', 'structured', 'knowledge', '.', 'From', 'sentiment', 'analysis', 'to', 'topic', 'modeling', ',', 'text', 'analytics', 'unlocks', 'a', 'wealth', 'of', 'possibilities', 'for', 'understanding', 'human', 'behavior', ',', 'informing', 'decision-making', ',', 'and', 'driving', 'innovation.In', 'the', 'realm', 'of', 'commerce', ',', 'businesses', 'harness', 'the', 'power', 'of', 'text', 'analytics', 'to', 'glean', 'insights', 'from', 'customer', 'feedback', ',', 'predict', 'market', 'trends', ',', 'and', 'personalize', 'user', 'experiences', '.', 'Social', 'scientists', 'explore', 'digital', 'archives', 'to', 'study', 'cultural', 'shifts', ',', 'linguistic', 'evolution', ',', 'and', 'societal', 'dynamics', '.', 'Healthcare', 'professionals', 'employ', 'text', 'mining', 'techniques', 'to', 'analyze', 'medical', 'records', ',', 'detect', 'patterns', 'in', 'patient', 'symptoms', ',', 'and', 'enhance', 'diagnostic', 'accuracy', '.', 'Meanwhile', ',', 'policymakers', 'turn', 'to', 'text', 'analytics', 'to', 'monitor', 'public', 'opinion', ',', 'track', 'emerging', 'issues', ',', 'and', 'inform', 'governance', 'strategies.As', 'the', 'digital', 'landscape', 'continues', 'to', 'evolve', 'and', 'expand', ',', 'so', 'too', 'does', 'the', 'field', 'of', 'text', 'analytics', ',', 'pushing', 'the', 'boundaries', 'of', 'what', 'is', 'possible', 'in', 'the', 'realm', 'of', 'language', 'understanding', '.', 'With', 'each', 'passing', 'day', ',', 'new', 'technologies', 'emerge', ',', 'new', 'methodologies', 'evolve', ',', 'and', 'new', 'frontiers', 'beckon', ',', 'inviting', 'explorers', 'to', 'venture', 'forth', 'into', 'the', 'uncharted', 'territories', 'of', 'the', 'digital', 'wilderness', '.', 'And', 'as', 'they', 'do', ',', 'they', 'carry', 'with', 'them', 'the', 'torch', 'of', 'knowledge', ',', 'illuminating', 'the', 'path', 'ahead', 'and', 'shedding', 'light', 'on', 'the', 'mysteries', 'that', 'lie', 'beyond', '.']\n",
      "Sentence Tokenization\n",
      "['In the vast expanse of the digital realm, where information flows ceaselessly and boundaries blur between reality and virtuality, lies an intricate tapestry of interconnected nodes and networks.', 'Within this labyrinthine landscape, individuals navigate the ever-shifting currents of data, seeking meaning amidst the chaos.', 'From the bustling streets of social media platforms to the serene corridors of scholarly archives, voices echo and ideas converge in a symphony of diversity.', 'Algorithms hum in the background, orchestrating the flow of content and shaping the digital discourse.', 'Yet, amidst the noise, patterns emerge, revealing glimpses of insight and understanding.At the heart of this digital ecosystem lies the art and science of text analytics, a discipline dedicated to unraveling the mysteries hidden within the written word.', 'Armed with computational tools and linguistic expertise, analysts embark on a journey of discovery, sifting through vast troves of textual data in search of nuggets of wisdom.', 'Natural language processing algorithms parse sentences, extract entities, and discern sentiments, transforming raw text into structured knowledge.', 'From sentiment analysis to topic modeling, text analytics unlocks a wealth of possibilities for understanding human behavior, informing decision-making, and driving innovation.In the realm of commerce, businesses harness the power of text analytics to glean insights from customer feedback, predict market trends, and personalize user experiences.', 'Social scientists explore digital archives to study cultural shifts, linguistic evolution, and societal dynamics.', 'Healthcare professionals employ text mining techniques to analyze medical records, detect patterns in patient symptoms, and enhance diagnostic accuracy.', 'Meanwhile, policymakers turn to text analytics to monitor public opinion, track emerging issues, and inform governance strategies.As the digital landscape continues to evolve and expand, so too does the field of text analytics, pushing the boundaries of what is possible in the realm of language understanding.', 'With each passing day, new technologies emerge, new methodologies evolve, and new frontiers beckon, inviting explorers to venture forth into the uncharted territories of the digital wilderness.', 'And as they do, they carry with them the torch of knowledge, illuminating the path ahead and shedding light on the mysteries that lie beyond.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization - Tokenization is the process of splitting a text or document into smaller units called tokens. These tokens can be words, phrases, or symbols, depending on the specific tokenizer used. \n",
    "\n",
    "# Word Tokenization\n",
    "print(\"Word Tokenization\")\n",
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens)\n",
    "\n",
    "# Sentence Tokenization\n",
    "print(\"Sentence Tokenization\")\n",
    "sentence_tokens = sent_tokenize(text)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadc4988-fd7c-4c1f-a0f8-40df48621a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('the', 'DT'), ('vast', 'JJ'), ('expanse', 'NN'), ('of', 'IN'), ('the', 'DT'), ('digital', 'JJ'), ('realm', 'NN'), (',', ','), ('where', 'WRB'), ('information', 'NN'), ('flows', 'VBZ'), ('ceaselessly', 'RB'), ('and', 'CC'), ('boundaries', 'NNS'), ('blur', 'VBP'), ('between', 'IN'), ('reality', 'NN'), ('and', 'CC'), ('virtuality', 'NN'), (',', ','), ('lies', 'VBZ'), ('an', 'DT'), ('intricate', 'JJ'), ('tapestry', 'NN'), ('of', 'IN'), ('interconnected', 'JJ'), ('nodes', 'NNS'), ('and', 'CC'), ('networks', 'NNS'), ('.', '.'), ('Within', 'IN'), ('this', 'DT'), ('labyrinthine', 'JJ'), ('landscape', 'NN'), (',', ','), ('individuals', 'NNS'), ('navigate', 'VBP'), ('the', 'DT'), ('ever-shifting', 'JJ'), ('currents', 'NNS'), ('of', 'IN'), ('data', 'NNS'), (',', ','), ('seeking', 'VBG'), ('meaning', 'NN'), ('amidst', 'IN'), ('the', 'DT'), ('chaos', 'NN'), ('.', '.'), ('From', 'IN'), ('the', 'DT'), ('bustling', 'VBG'), ('streets', 'NNS'), ('of', 'IN'), ('social', 'JJ'), ('media', 'NNS'), ('platforms', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('serene', 'JJ'), ('corridors', 'NNS'), ('of', 'IN'), ('scholarly', 'JJ'), ('archives', 'NNS'), (',', ','), ('voices', 'NNS'), ('echo', 'VBP'), ('and', 'CC'), ('ideas', 'NNS'), ('converge', 'VBP'), ('in', 'IN'), ('a', 'DT'), ('symphony', 'NN'), ('of', 'IN'), ('diversity', 'NN'), ('.', '.'), ('Algorithms', 'NNP'), ('hum', 'NN'), ('in', 'IN'), ('the', 'DT'), ('background', 'NN'), (',', ','), ('orchestrating', 'VBG'), ('the', 'DT'), ('flow', 'NN'), ('of', 'IN'), ('content', 'NN'), ('and', 'CC'), ('shaping', 'VBG'), ('the', 'DT'), ('digital', 'JJ'), ('discourse', 'NN'), ('.', '.'), ('Yet', 'CC'), (',', ','), ('amidst', 'VBZ'), ('the', 'DT'), ('noise', 'NN'), (',', ','), ('patterns', 'VBZ'), ('emerge', 'NN'), (',', ','), ('revealing', 'VBG'), ('glimpses', 'NNS'), ('of', 'IN'), ('insight', 'NN'), ('and', 'CC'), ('understanding.At', 'VB'), ('the', 'DT'), ('heart', 'NN'), ('of', 'IN'), ('this', 'DT'), ('digital', 'JJ'), ('ecosystem', 'NN'), ('lies', 'VBZ'), ('the', 'DT'), ('art', 'NN'), ('and', 'CC'), ('science', 'NN'), ('of', 'IN'), ('text', 'NN'), ('analytics', 'NNS'), (',', ','), ('a', 'DT'), ('discipline', 'NN'), ('dedicated', 'VBN'), ('to', 'TO'), ('unraveling', 'VBG'), ('the', 'DT'), ('mysteries', 'NNS'), ('hidden', 'VBP'), ('within', 'IN'), ('the', 'DT'), ('written', 'VBN'), ('word', 'NN'), ('.', '.'), ('Armed', 'VBN'), ('with', 'IN'), ('computational', 'JJ'), ('tools', 'NNS'), ('and', 'CC'), ('linguistic', 'JJ'), ('expertise', 'NN'), (',', ','), ('analysts', 'NNS'), ('embark', 'VBP'), ('on', 'IN'), ('a', 'DT'), ('journey', 'NN'), ('of', 'IN'), ('discovery', 'NN'), (',', ','), ('sifting', 'VBG'), ('through', 'IN'), ('vast', 'JJ'), ('troves', 'NNS'), ('of', 'IN'), ('textual', 'JJ'), ('data', 'NNS'), ('in', 'IN'), ('search', 'NN'), ('of', 'IN'), ('nuggets', 'NNS'), ('of', 'IN'), ('wisdom', 'NN'), ('.', '.'), ('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('algorithms', 'JJ'), ('parse', 'NN'), ('sentences', 'NNS'), (',', ','), ('extract', 'JJ'), ('entities', 'NNS'), (',', ','), ('and', 'CC'), ('discern', 'JJ'), ('sentiments', 'NNS'), (',', ','), ('transforming', 'VBG'), ('raw', 'JJ'), ('text', 'NN'), ('into', 'IN'), ('structured', 'VBN'), ('knowledge', 'NN'), ('.', '.'), ('From', 'IN'), ('sentiment', 'NN'), ('analysis', 'NN'), ('to', 'TO'), ('topic', 'VB'), ('modeling', 'NN'), (',', ','), ('text', 'NN'), ('analytics', 'NNS'), ('unlocks', 'VBZ'), ('a', 'DT'), ('wealth', 'NN'), ('of', 'IN'), ('possibilities', 'NNS'), ('for', 'IN'), ('understanding', 'VBG'), ('human', 'JJ'), ('behavior', 'NN'), (',', ','), ('informing', 'VBG'), ('decision-making', 'NN'), (',', ','), ('and', 'CC'), ('driving', 'VBG'), ('innovation.In', 'VB'), ('the', 'DT'), ('realm', 'NN'), ('of', 'IN'), ('commerce', 'NN'), (',', ','), ('businesses', 'NNS'), ('harness', 'VBP'), ('the', 'DT'), ('power', 'NN'), ('of', 'IN'), ('text', 'NN'), ('analytics', 'NNS'), ('to', 'TO'), ('glean', 'VB'), ('insights', 'NNS'), ('from', 'IN'), ('customer', 'NN'), ('feedback', 'NN'), (',', ','), ('predict', 'VBP'), ('market', 'NN'), ('trends', 'NNS'), (',', ','), ('and', 'CC'), ('personalize', 'VB'), ('user', 'JJ'), ('experiences', 'NNS'), ('.', '.'), ('Social', 'JJ'), ('scientists', 'NNS'), ('explore', 'VBP'), ('digital', 'JJ'), ('archives', 'NNS'), ('to', 'TO'), ('study', 'VB'), ('cultural', 'JJ'), ('shifts', 'NNS'), (',', ','), ('linguistic', 'JJ'), ('evolution', 'NN'), (',', ','), ('and', 'CC'), ('societal', 'JJ'), ('dynamics', 'NNS'), ('.', '.'), ('Healthcare', 'NNP'), ('professionals', 'NNS'), ('employ', 'VBP'), ('text', 'NN'), ('mining', 'NN'), ('techniques', 'NNS'), ('to', 'TO'), ('analyze', 'VB'), ('medical', 'JJ'), ('records', 'NNS'), (',', ','), ('detect', 'NN'), ('patterns', 'NNS'), ('in', 'IN'), ('patient', 'NN'), ('symptoms', 'NNS'), (',', ','), ('and', 'CC'), ('enhance', 'VB'), ('diagnostic', 'JJ'), ('accuracy', 'NN'), ('.', '.'), ('Meanwhile', 'RB'), (',', ','), ('policymakers', 'NNS'), ('turn', 'VBP'), ('to', 'TO'), ('text', 'VB'), ('analytics', 'NNS'), ('to', 'TO'), ('monitor', 'VB'), ('public', 'JJ'), ('opinion', 'NN'), (',', ','), ('track', 'NN'), ('emerging', 'VBG'), ('issues', 'NNS'), (',', ','), ('and', 'CC'), ('inform', 'VB'), ('governance', 'NN'), ('strategies.As', 'PDT'), ('the', 'DT'), ('digital', 'JJ'), ('landscape', 'NN'), ('continues', 'VBZ'), ('to', 'TO'), ('evolve', 'VB'), ('and', 'CC'), ('expand', 'VB'), (',', ','), ('so', 'RB'), ('too', 'RB'), ('does', 'VBZ'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('analytics', 'NNS'), (',', ','), ('pushing', 'VBG'), ('the', 'DT'), ('boundaries', 'NNS'), ('of', 'IN'), ('what', 'WP'), ('is', 'VBZ'), ('possible', 'JJ'), ('in', 'IN'), ('the', 'DT'), ('realm', 'NN'), ('of', 'IN'), ('language', 'NN'), ('understanding', 'NN'), ('.', '.'), ('With', 'IN'), ('each', 'DT'), ('passing', 'NN'), ('day', 'NN'), (',', ','), ('new', 'JJ'), ('technologies', 'NNS'), ('emerge', 'VBP'), (',', ','), ('new', 'JJ'), ('methodologies', 'NNS'), ('evolve', 'VBP'), (',', ','), ('and', 'CC'), ('new', 'JJ'), ('frontiers', 'NNS'), ('beckon', 'VBP'), (',', ','), ('inviting', 'VBG'), ('explorers', 'NNS'), ('to', 'TO'), ('venture', 'NN'), ('forth', 'NN'), ('into', 'IN'), ('the', 'DT'), ('uncharted', 'JJ'), ('territories', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('digital', 'JJ'), ('wilderness', 'NN'), ('.', '.'), ('And', 'CC'), ('as', 'IN'), ('they', 'PRP'), ('do', 'VBP'), (',', ','), ('they', 'PRP'), ('carry', 'VBP'), ('with', 'IN'), ('them', 'PRP'), ('the', 'DT'), ('torch', 'NN'), ('of', 'IN'), ('knowledge', 'NN'), (',', ','), ('illuminating', 'VBG'), ('the', 'DT'), ('path', 'NN'), ('ahead', 'RB'), ('and', 'CC'), ('shedding', 'VBG'), ('light', 'NN'), ('on', 'IN'), ('the', 'DT'), ('mysteries', 'NNS'), ('that', 'WDT'), ('lie', 'VBP'), ('beyond', 'IN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging - POS tagging is the process of assigning a part-of-speech tag (e.g., noun, verb, adjective) to each token in a sentence. It helps in understanding the grammatical structure of a sentence\n",
    "\n",
    "tags = pos_tag(word_tokens)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5180afea-1b88-49a3-91ae-d46b26aeebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'its', 'am', 's', 'couldn', \"that'll\", 'were', 'did', 'do', 'under', 'more', 'with', \"needn't\", 'over', 'whom', 'for', 'those', 'needn', 'about', 'as', 'now', 'who', 'don', 'all', 'isn', 'other', 'haven', 'their', 'himself', \"wouldn't\", 'where', 'nor', 'will', 'from', 'these', 'until', 'and', 'after', 'how', \"you've\", 're', \"it's\", 'we', 'ain', 'during', 'yourself', 'at', 'through', 'no', 'been', 'll', 'that', 'only', 'doesn', 'didn', 'on', \"wasn't\", 'too', 'is', 'have', 'than', 'it', 'aren', 'mightn', ',', 'why', 'herself', 'against', 'myself', 'she', 'was', \"isn't\", 'does', 'themselves', 'be', 'd', 'into', 'below', 'my', 'here', 'they', 'again', 'few', '.', \"you're\", \"didn't\", 'most', 'down', 'when', \"aren't\", 'own', 'off', 'should', 'but', \"you'd\", 'very', 'theirs', 'a', 'up', \"weren't\", 'i', 'weren', 'to', 'doing', 'further', 'can', 'won', 'wouldn', 'itself', 'in', \"she's\", \"hadn't\", 'because', 'are', 'him', 'or', 'such', 'had', 'her', 'being', 'while', 'hers', 'before', 'yours', \"hasn't\", 'shouldn', 'of', 'our', 'mustn', \"doesn't\", 'each', 'hasn', \"you'll\", 'having', 'this', 'then', 'not', 'out', \"mustn't\", \"should've\", 'both', 'what', \"shan't\", 'yourselves', 'any', 'some', \"won't\", 'has', 'm', 'his', 'he', 'them', 'ourselves', 'between', 'ma', 've', \"mightn't\", 'your', \"haven't\", \"couldn't\", 'an', 'just', 'by', \"shouldn't\", 'if', 'y', 'o', 'hadn', 'so', 'wasn', 'me', 'ours', 'you', 'above', 'shan', 't', 'the', 'once', \"don't\", 'there', 'which', 'same'}\n",
      "Filtered Words after removal of stop words.\n",
      "['vast', 'expanse', 'digital', 'realm', 'information', 'flows', 'ceaselessly', 'boundaries', 'blur', 'reality', 'virtuality', 'lies', 'intricate', 'tapestry', 'interconnected', 'nodes', 'networks', 'within', 'labyrinthine', 'landscape', 'individuals', 'navigate', 'ever-shifting', 'currents', 'data', 'seeking', 'meaning', 'amidst', 'chaos', 'bustling', 'streets', 'social', 'media', 'platforms', 'serene', 'corridors', 'scholarly', 'archives', 'voices', 'echo', 'ideas', 'converge', 'symphony', 'diversity', 'algorithms', 'hum', 'background', 'orchestrating', 'flow', 'content', 'shaping', 'digital', 'discourse', 'yet', 'amidst', 'noise', 'patterns', 'emerge', 'revealing', 'glimpses', 'insight', 'understanding.at', 'heart', 'digital', 'ecosystem', 'lies', 'art', 'science', 'text', 'analytics', 'discipline', 'dedicated', 'unraveling', 'mysteries', 'hidden', 'within', 'written', 'word', 'armed', 'computational', 'tools', 'linguistic', 'expertise', 'analysts', 'embark', 'journey', 'discovery', 'sifting', 'vast', 'troves', 'textual', 'data', 'search', 'nuggets', 'wisdom', 'natural', 'language', 'processing', 'algorithms', 'parse', 'sentences', 'extract', 'entities', 'discern', 'sentiments', 'transforming', 'raw', 'text', 'structured', 'knowledge', 'sentiment', 'analysis', 'topic', 'modeling', 'text', 'analytics', 'unlocks', 'wealth', 'possibilities', 'understanding', 'human', 'behavior', 'informing', 'decision-making', 'driving', 'innovation.in', 'realm', 'commerce', 'businesses', 'harness', 'power', 'text', 'analytics', 'glean', 'insights', 'customer', 'feedback', 'predict', 'market', 'trends', 'personalize', 'user', 'experiences', 'social', 'scientists', 'explore', 'digital', 'archives', 'study', 'cultural', 'shifts', 'linguistic', 'evolution', 'societal', 'dynamics', 'healthcare', 'professionals', 'employ', 'text', 'mining', 'techniques', 'analyze', 'medical', 'records', 'detect', 'patterns', 'patient', 'symptoms', 'enhance', 'diagnostic', 'accuracy', 'meanwhile', 'policymakers', 'turn', 'text', 'analytics', 'monitor', 'public', 'opinion', 'track', 'emerging', 'issues', 'inform', 'governance', 'strategies.as', 'digital', 'landscape', 'continues', 'evolve', 'expand', 'field', 'text', 'analytics', 'pushing', 'boundaries', 'possible', 'realm', 'language', 'understanding', 'passing', 'day', 'new', 'technologies', 'emerge', 'new', 'methodologies', 'evolve', 'new', 'frontiers', 'beckon', 'inviting', 'explorers', 'venture', 'forth', 'uncharted', 'territories', 'digital', 'wilderness', 'carry', 'torch', 'knowledge', 'illuminating', 'path', 'ahead', 'shedding', 'light', 'mysteries', 'lie', 'beyond']\n"
     ]
    }
   ],
   "source": [
    "# Stop Words Removal - Stop words are common words that are often filtered out from text data because they do not contribute much to the meaning of the text. These words include articles, prepositions, conjunctions, and other common words.\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(\".\")\n",
    "stop_words.add(\",\")\n",
    "print(stop_words)\n",
    "\n",
    "print(\"Filtered Words after removal of stop words.\")\n",
    "filtered_words = []\n",
    "for word in word_tokens:\n",
    "    if word.lower() not in stop_words:\n",
    "        filtered_words.append(word.lower())\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478f9196-3ddc-42d5-bafb-13e48a68088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming\n",
      "['vast', 'expans', 'digit', 'realm', 'inform', 'flow', 'ceaselessli', 'boundari', 'blur', 'realiti', 'virtual', 'lie', 'intric', 'tapestri', 'interconnect', 'node', 'network', 'within', 'labyrinthin', 'landscap', 'individu', 'navig', 'ever-shift', 'current', 'data', 'seek', 'mean', 'amidst', 'chao', 'bustl', 'street', 'social', 'media', 'platform', 'seren', 'corridor', 'scholarli', 'archiv', 'voic', 'echo', 'idea', 'converg', 'symphoni', 'divers', 'algorithm', 'hum', 'background', 'orchestr', 'flow', 'content', 'shape', 'digit', 'discours', 'yet', 'amidst', 'nois', 'pattern', 'emerg', 'reveal', 'glimps', 'insight', 'understanding.at', 'heart', 'digit', 'ecosystem', 'lie', 'art', 'scienc', 'text', 'analyt', 'disciplin', 'dedic', 'unravel', 'mysteri', 'hidden', 'within', 'written', 'word', 'arm', 'comput', 'tool', 'linguist', 'expertis', 'analyst', 'embark', 'journey', 'discoveri', 'sift', 'vast', 'trove', 'textual', 'data', 'search', 'nugget', 'wisdom', 'natur', 'languag', 'process', 'algorithm', 'pars', 'sentenc', 'extract', 'entiti', 'discern', 'sentiment', 'transform', 'raw', 'text', 'structur', 'knowledg', 'sentiment', 'analysi', 'topic', 'model', 'text', 'analyt', 'unlock', 'wealth', 'possibl', 'understand', 'human', 'behavior', 'inform', 'decision-mak', 'drive', 'innovation.in', 'realm', 'commerc', 'busi', 'har', 'power', 'text', 'analyt', 'glean', 'insight', 'custom', 'feedback', 'predict', 'market', 'trend', 'person', 'user', 'experi', 'social', 'scientist', 'explor', 'digit', 'archiv', 'studi', 'cultur', 'shift', 'linguist', 'evolut', 'societ', 'dynam', 'healthcar', 'profession', 'employ', 'text', 'mine', 'techniqu', 'analyz', 'medic', 'record', 'detect', 'pattern', 'patient', 'symptom', 'enhanc', 'diagnost', 'accuraci', 'meanwhil', 'policymak', 'turn', 'text', 'analyt', 'monitor', 'public', 'opinion', 'track', 'emerg', 'issu', 'inform', 'govern', 'strategies.a', 'digit', 'landscap', 'continu', 'evolv', 'expand', 'field', 'text', 'analyt', 'push', 'boundari', 'possibl', 'realm', 'languag', 'understand', 'pass', 'day', 'new', 'technolog', 'emerg', 'new', 'methodolog', 'evolv', 'new', 'frontier', 'beckon', 'invit', 'explor', 'ventur', 'forth', 'unchart', 'territori', 'digit', 'wilder', 'carri', 'torch', 'knowledg', 'illumin', 'path', 'ahead', 'shed', 'light', 'mysteri', 'lie', 'beyond']\n"
     ]
    }
   ],
   "source": [
    "# Stemming - Stemming is the process of reducing words to their root or base form by removing affixes (e.g., prefixes, suffixes). The goal of stemming is to reduce words to their common base or root form, which helps in information retrieval and text analysis. Stemming is a process that stems or removes last few characters from a word, often leading to incorrect meanings and spelling.\n",
    "\n",
    "print(\"Stemming\")\n",
    "porter = PorterStemmer()\n",
    "stemmed_tokens = []\n",
    "for word in filtered_words:\n",
    "    stemmed_tokens.append(porter.stem(word))\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61b5d1a-7103-46b6-8050-a797e49860e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization\n",
      "['vast', 'expanse', 'digital', 'realm', 'information', 'flow', 'ceaselessly', 'boundary', 'blur', 'reality', 'virtuality', 'lie', 'intricate', 'tapestry', 'interconnected', 'node', 'network', 'within', 'labyrinthine', 'landscape', 'individual', 'navigate', 'ever-shifting', 'current', 'data', 'seeking', 'meaning', 'amidst', 'chaos', 'bustling', 'street', 'social', 'medium', 'platform', 'serene', 'corridor', 'scholarly', 'archive', 'voice', 'echo', 'idea', 'converge', 'symphony', 'diversity', 'algorithm', 'hum', 'background', 'orchestrating', 'flow', 'content', 'shaping', 'digital', 'discourse', 'yet', 'amidst', 'noise', 'pattern', 'emerge', 'revealing', 'glimpse', 'insight', 'understanding.at', 'heart', 'digital', 'ecosystem', 'lie', 'art', 'science', 'text', 'analytics', 'discipline', 'dedicated', 'unraveling', 'mystery', 'hidden', 'within', 'written', 'word', 'armed', 'computational', 'tool', 'linguistic', 'expertise', 'analyst', 'embark', 'journey', 'discovery', 'sifting', 'vast', 'trove', 'textual', 'data', 'search', 'nugget', 'wisdom', 'natural', 'language', 'processing', 'algorithm', 'parse', 'sentence', 'extract', 'entity', 'discern', 'sentiment', 'transforming', 'raw', 'text', 'structured', 'knowledge', 'sentiment', 'analysis', 'topic', 'modeling', 'text', 'analytics', 'unlocks', 'wealth', 'possibility', 'understanding', 'human', 'behavior', 'informing', 'decision-making', 'driving', 'innovation.in', 'realm', 'commerce', 'business', 'harness', 'power', 'text', 'analytics', 'glean', 'insight', 'customer', 'feedback', 'predict', 'market', 'trend', 'personalize', 'user', 'experience', 'social', 'scientist', 'explore', 'digital', 'archive', 'study', 'cultural', 'shift', 'linguistic', 'evolution', 'societal', 'dynamic', 'healthcare', 'professional', 'employ', 'text', 'mining', 'technique', 'analyze', 'medical', 'record', 'detect', 'pattern', 'patient', 'symptom', 'enhance', 'diagnostic', 'accuracy', 'meanwhile', 'policymakers', 'turn', 'text', 'analytics', 'monitor', 'public', 'opinion', 'track', 'emerging', 'issue', 'inform', 'governance', 'strategies.as', 'digital', 'landscape', 'continues', 'evolve', 'expand', 'field', 'text', 'analytics', 'pushing', 'boundary', 'possible', 'realm', 'language', 'understanding', 'passing', 'day', 'new', 'technology', 'emerge', 'new', 'methodology', 'evolve', 'new', 'frontier', 'beckon', 'inviting', 'explorer', 'venture', 'forth', 'uncharted', 'territory', 'digital', 'wilderness', 'carry', 'torch', 'knowledge', 'illuminating', 'path', 'ahead', 'shedding', 'light', 'mystery', 'lie', 'beyond']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization - Lemmatization is similar to stemming but involves reducing words to their base or dictionary form (lemma) using a vocabulary and morphological analysis of the words. Lemmatization ensures that the resulting word is a valid word. Lemmatization considers the context and converts the word to its meaningful base form, which is called Lemma.\n",
    "\n",
    "print(\"Lemmatization\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmetized_tokens = []\n",
    "for word in filtered_words:\n",
    "    lemmetized_tokens.append(lemmatizer.lemmatize(word))\n",
    "print(lemmetized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077f5deb-fb0d-4e60-bfad-29b5e9e55ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Frequency - Measures how frequently a term appears in a document. TF measures the frequency of a term (word) in a document relative to the total number of words in that document.\n",
    "# TF = (freq of term in a doc / total number of terms in doc)\n",
    "\n",
    "# Inverse Document Frequency - IDF measures the rarity of a term across all documents in the corpus.\n",
    "# IDF = log(totalno of docs / no of docs containing the term + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b0969d-345f-4e3b-9aef-5cce8eb77026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understand : 0.014814814814814815\n",
      "analysis : 0.007407407407407408\n",
      "ambiguity : 0.007407407407407408\n",
      "wide : 0.007407407407407408\n",
      "concerned : 0.007407407407407408\n",
      ") : 0.007407407407407408\n",
      "with : 0.014814814814814815\n",
      "techniques : 0.007407407407407408\n",
      "for : 0.007407407407407408\n",
      "language : 0.02962962962962963\n",
      "summarization : 0.007407407407407408\n",
      "artificial : 0.007407407407407408\n",
      "intelligence : 0.007407407407407408\n",
      "research : 0.007407407407407408\n",
      "make : 0.007407407407407408\n",
      "dealing : 0.007407407407407408\n",
      "field : 0.007407407407407408\n",
      "and : 0.05925925925925926\n",
      "advances : 0.007407407407407408\n",
      "deep : 0.007407407407407408\n",
      "generate : 0.007407407407407408\n",
      "computers : 0.022222222222222223\n",
      "Natural : 0.007407407407407408\n",
      "that : 0.007407407407407408\n",
      "translation : 0.007407407407407408\n",
      "accurately : 0.007407407407407408\n",
      "increasingly : 0.007407407407407408\n",
      "One : 0.007407407407407408\n",
      "applications : 0.007407407407407408\n",
      "is : 0.022222222222222223\n",
      "have : 0.007407407407407408\n",
      "it : 0.014814814814814815\n",
      "important : 0.007407407407407408\n",
      ", : 0.06666666666666667\n",
      "improvements : 0.007407407407407408\n",
      ". : 0.037037037037037035\n",
      "However : 0.007407407407407408\n",
      "human : 0.007407407407407408\n",
      "range : 0.007407407407407408\n",
      "key : 0.007407407407407408\n",
      "learning : 0.014814814814814815\n",
      "process : 0.007407407407407408\n",
      "a : 0.022222222222222223\n",
      "enable : 0.007407407407407408\n",
      "area : 0.007407407407407408\n",
      "to : 0.02962962962962963\n",
      "recent : 0.007407407407407408\n",
      "performance : 0.007407407407407408\n",
      "NLP : 0.02962962962962963\n",
      "used : 0.007407407407407408\n",
      "can : 0.007407407407407408\n",
      "aims : 0.007407407407407408\n",
      "difficult : 0.007407407407407408\n",
      "interaction : 0.007407407407407408\n",
      "in : 0.044444444444444446\n",
      "are : 0.007407407407407408\n",
      "useful : 0.007407407407407408\n",
      "development : 0.007407407407407408\n",
      "led : 0.007407407407407408\n",
      "meaningful : 0.007407407407407408\n",
      "including : 0.007407407407407408\n",
      "text : 0.014814814814814815\n",
      "of : 0.037037037037037035\n",
      "humans : 0.007407407407407408\n",
      "interpret : 0.007407407407407408\n",
      "extraction : 0.007407407407407408\n",
      "variability : 0.007407407407407408\n",
      "It : 0.007407407407407408\n",
      "both : 0.007407407407407408\n",
      "natural : 0.014814814814814815\n",
      "information : 0.007407407407407408\n",
      "significant : 0.007407407407407408\n",
      "processing : 0.007407407407407408\n",
      "between : 0.007407407407407408\n",
      "( : 0.007407407407407408\n",
      "making : 0.007407407407407408\n",
      "an : 0.007407407407407408\n",
      "sentiment : 0.007407407407407408\n",
      "the : 0.022222222222222223\n",
      "challenges : 0.007407407407407408\n",
      "way : 0.007407407407407408\n",
      "machine : 0.014814814814814815\n",
      "which : 0.007407407407407408\n",
      "type : 0.008620689655172414\n",
      "algorithms : 0.017241379310344827\n",
      "model : 0.017241379310344827\n",
      "labeled : 0.008620689655172414\n",
      "learning : 0.06896551724137931\n",
      "environment : 0.008620689655172414\n",
      "task : 0.008620689655172414\n",
      "categorized : 0.008620689655172414\n",
      "interact : 0.008620689655172414\n",
      "image : 0.008620689655172414\n",
      "vehicles : 0.008620689655172414\n",
      "that : 0.017241379310344827\n",
      "training : 0.034482758620689655\n",
      "unlabeled : 0.008620689655172414\n",
      "a : 0.02586206896551724\n",
      "on : 0.04310344827586207\n",
      "focuses : 0.008620689655172414\n",
      ") : 0.008620689655172414\n",
      "with : 0.008620689655172414\n",
      "to : 0.008620689655172414\n",
      "based : 0.008620689655172414\n",
      "applications : 0.008620689655172414\n",
      "is : 0.008620689655172414\n",
      "have : 0.008620689655172414\n",
      "techniques : 0.008620689655172414\n",
      "recognition : 0.017241379310344827\n",
      "Supervised : 0.008620689655172414\n",
      "Machine : 0.008620689655172414\n",
      ", : 0.06896551724137931\n",
      "( : 0.008620689655172414\n",
      "can : 0.017241379310344827\n",
      "data : 0.034482758620689655\n",
      "diagnosis : 0.008620689655172414\n",
      "Reinforcement : 0.008620689655172414\n",
      "be : 0.008620689655172414\n",
      "artificial : 0.008620689655172414\n",
      "autonomous : 0.008620689655172414\n",
      "in : 0.008620689655172414\n",
      "various : 0.008620689655172414\n",
      "intelligence : 0.008620689655172414\n",
      "an : 0.008620689655172414\n",
      "ML : 0.02586206896551724\n",
      "speech : 0.008620689655172414\n",
      "into : 0.008620689655172414\n",
      "reinforcement : 0.008620689655172414\n",
      "predictions : 0.008620689655172414\n",
      "unsupervised : 0.017241379310344827\n",
      "or : 0.008620689655172414\n",
      ". : 0.04310344827586207\n",
      "feedback : 0.008620689655172414\n",
      "development : 0.008620689655172414\n",
      "while : 0.008620689655172414\n",
      "make : 0.008620689655172414\n",
      "including : 0.008620689655172414\n",
      "supervised : 0.008620689655172414\n",
      "involves : 0.02586206896551724\n",
      "from : 0.017241379310344827\n",
      "subset : 0.008620689655172414\n",
      "of : 0.02586206896551724\n",
      "the : 0.02586206896551724\n",
      "domains : 0.008620689655172414\n",
      "learn : 0.017241379310344827\n",
      "and : 0.04310344827586207\n",
      "depending : 0.008620689655172414\n",
      "medical : 0.008620689655172414\n",
      "decisions : 0.008620689655172414\n",
      "mining : 0.009900990099009901\n",
      "statistics : 0.009900990099009901\n",
      "e-commerce : 0.009900990099009901\n",
      "data-driven : 0.009900990099009901\n",
      "interdisciplinary : 0.009900990099009901\n",
      "tools : 0.009900990099009901\n",
      "machine : 0.009900990099009901\n",
      "use : 0.009900990099009901\n",
      "learning : 0.009900990099009901\n",
      "analysis : 0.009900990099009901\n",
      "has : 0.009900990099009901\n",
      "decisions : 0.009900990099009901\n",
      "that : 0.009900990099009901\n",
      "Data : 0.0297029702970297\n",
      "uncover : 0.009900990099009901\n",
      "a : 0.009900990099009901\n",
      "patterns : 0.009900990099009901\n",
      "trends : 0.009900990099009901\n",
      "collection : 0.009900990099009901\n",
      "to : 0.019801980198019802\n",
      "marketing : 0.009900990099009901\n",
      "applications : 0.009900990099009901\n",
      "is : 0.009900990099009901\n",
      "cleaning : 0.009900990099009901\n",
      "techniques : 0.019801980198019802\n",
      ", : 0.13861386138613863\n",
      "extract : 0.009900990099009901\n",
      "data : 0.07920792079207921\n",
      "industries : 0.009900990099009901\n",
      "as : 0.009900990099009901\n",
      "statistical : 0.009900990099009901\n",
      "in : 0.019801980198019802\n",
      "various : 0.009900990099009901\n",
      "an : 0.009900990099009901\n",
      "knowledge : 0.019801980198019802\n",
      "insights : 0.009900990099009901\n",
      "computer : 0.009900990099009901\n",
      "numerous : 0.009900990099009901\n",
      "stages : 0.009900990099009901\n",
      "modeling : 0.009900990099009901\n",
      ". : 0.039603960396039604\n",
      "scientists : 0.009900990099009901\n",
      "such : 0.009900990099009901\n",
      "make : 0.009900990099009901\n",
      "finance : 0.009900990099009901\n",
      "including : 0.019801980198019802\n",
      "visualization : 0.009900990099009901\n",
      "involves : 0.009900990099009901\n",
      "from : 0.019801980198019802\n",
      "healthcare : 0.009900990099009901\n",
      "science : 0.0297029702970297\n",
      "combines : 0.009900990099009901\n",
      "of : 0.019801980198019802\n",
      "the : 0.009900990099009901\n",
      "domain-specific : 0.009900990099009901\n",
      "variety : 0.009900990099009901\n",
      "field : 0.009900990099009901\n",
      "and : 0.07920792079207921\n",
      "lifecycle : 0.009900990099009901\n",
      "It : 0.009900990099009901\n",
      "type : 0.4054651081081644\n",
      "understand : 0.4054651081081644\n",
      "task : 0.4054651081081644\n",
      "analysis : 0.0\n",
      "ambiguity : 0.4054651081081644\n",
      "image : 0.4054651081081644\n",
      "wide : 0.4054651081081644\n",
      "training : 0.4054651081081644\n",
      "unlabeled : 0.4054651081081644\n",
      "concerned : 0.4054651081081644\n",
      ") : 0.0\n",
      "with : 0.0\n",
      "techniques : -0.2876820724517809\n",
      "for : 0.4054651081081644\n",
      "language : 0.4054651081081644\n",
      "extract : 0.4054651081081644\n",
      "industries : 0.4054651081081644\n",
      "as : 0.4054651081081644\n",
      "summarization : 0.4054651081081644\n",
      "statistical : 0.4054651081081644\n",
      "artificial : 0.0\n",
      "intelligence : 0.0\n",
      "speech : 0.4054651081081644\n",
      "insights : 0.4054651081081644\n",
      "research : 0.4054651081081644\n",
      "stages : 0.4054651081081644\n",
      "modeling : 0.4054651081081644\n",
      "make : -0.2876820724517809\n",
      "supervised : 0.4054651081081644\n",
      "involves : 0.0\n",
      "dealing : 0.4054651081081644\n",
      "from : 0.0\n",
      "science : 0.4054651081081644\n",
      "combines : 0.4054651081081644\n",
      "field : 0.0\n",
      "and : -0.2876820724517809\n",
      "advances : 0.4054651081081644\n",
      "deep : 0.4054651081081644\n",
      "generate : 0.4054651081081644\n",
      "computers : 0.4054651081081644\n",
      "interdisciplinary : 0.4054651081081644\n",
      "tools : 0.4054651081081644\n",
      "Natural : 0.4054651081081644\n",
      "vehicles : 0.4054651081081644\n",
      "that : -0.2876820724517809\n",
      "translation : 0.4054651081081644\n",
      "on : 0.4054651081081644\n",
      "accurately : 0.4054651081081644\n",
      "increasingly : 0.4054651081081644\n",
      "One : 0.4054651081081644\n",
      "applications : -0.2876820724517809\n",
      "is : -0.2876820724517809\n",
      "have : 0.0\n",
      "it : 0.4054651081081644\n",
      "important : 0.4054651081081644\n",
      "Supervised : 0.4054651081081644\n",
      "Machine : 0.4054651081081644\n",
      ", : -0.2876820724517809\n",
      "improvements : 0.4054651081081644\n",
      "be : 0.4054651081081644\n",
      "autonomous : 0.4054651081081644\n",
      "various : 0.0\n",
      "into : 0.4054651081081644\n",
      "numerous : 0.4054651081081644\n",
      ". : -0.2876820724517809\n",
      "feedback : 0.4054651081081644\n",
      "However : 0.4054651081081644\n",
      "human : 0.4054651081081644\n",
      "range : 0.4054651081081644\n",
      "key : 0.4054651081081644\n",
      "learn : 0.4054651081081644\n",
      "decisions : 0.0\n",
      "statistics : 0.4054651081081644\n",
      "algorithms : 0.4054651081081644\n",
      "labeled : 0.4054651081081644\n",
      "learning : -0.2876820724517809\n",
      "process : 0.4054651081081644\n",
      "Data : 0.4054651081081644\n",
      "a : -0.2876820724517809\n",
      "enable : 0.4054651081081644\n",
      "area : 0.4054651081081644\n",
      "to : -0.2876820724517809\n",
      "based : 0.4054651081081644\n",
      "marketing : 0.4054651081081644\n",
      "cleaning : 0.4054651081081644\n",
      "recent : 0.4054651081081644\n",
      "performance : 0.4054651081081644\n",
      "NLP : 0.4054651081081644\n",
      "used : 0.4054651081081644\n",
      "can : 0.0\n",
      "data : 0.0\n",
      "aims : 0.4054651081081644\n",
      "difficult : 0.4054651081081644\n",
      "Reinforcement : 0.4054651081081644\n",
      "interaction : 0.4054651081081644\n",
      "in : -0.2876820724517809\n",
      "knowledge : 0.4054651081081644\n",
      "ML : 0.4054651081081644\n",
      "computer : 0.4054651081081644\n",
      "reinforcement : 0.4054651081081644\n",
      "are : 0.4054651081081644\n",
      "useful : 0.4054651081081644\n",
      "unsupervised : 0.4054651081081644\n",
      "or : 0.4054651081081644\n",
      "such : 0.4054651081081644\n",
      "development : 0.0\n",
      "led : 0.4054651081081644\n",
      "while : 0.4054651081081644\n",
      "meaningful : 0.4054651081081644\n",
      "including : -0.2876820724517809\n",
      "visualization : 0.4054651081081644\n",
      "text : 0.4054651081081644\n",
      "of : -0.2876820724517809\n",
      "humans : 0.4054651081081644\n",
      "domains : 0.4054651081081644\n",
      "domain-specific : 0.4054651081081644\n",
      "interpret : 0.4054651081081644\n",
      "extraction : 0.4054651081081644\n",
      "medical : 0.4054651081081644\n",
      "lifecycle : 0.4054651081081644\n",
      "variability : 0.4054651081081644\n",
      "It : 0.0\n",
      "both : 0.4054651081081644\n",
      "mining : 0.4054651081081644\n",
      "e-commerce : 0.4054651081081644\n",
      "data-driven : 0.4054651081081644\n",
      "model : 0.4054651081081644\n",
      "use : 0.4054651081081644\n",
      "environment : 0.4054651081081644\n",
      "categorized : 0.4054651081081644\n",
      "interact : 0.4054651081081644\n",
      "has : 0.4054651081081644\n",
      "natural : 0.4054651081081644\n",
      "uncover : 0.4054651081081644\n",
      "patterns : 0.4054651081081644\n",
      "trends : 0.4054651081081644\n",
      "focuses : 0.4054651081081644\n",
      "collection : 0.4054651081081644\n",
      "information : 0.4054651081081644\n",
      "significant : 0.4054651081081644\n",
      "recognition : 0.4054651081081644\n",
      "processing : 0.4054651081081644\n",
      "between : 0.4054651081081644\n",
      "( : 0.0\n",
      "diagnosis : 0.4054651081081644\n",
      "making : 0.4054651081081644\n",
      "an : -0.2876820724517809\n",
      "sentiment : 0.4054651081081644\n",
      "predictions : 0.4054651081081644\n",
      "scientists : 0.4054651081081644\n",
      "finance : 0.4054651081081644\n",
      "subset : 0.4054651081081644\n",
      "healthcare : 0.4054651081081644\n",
      "the : -0.2876820724517809\n",
      "challenges : 0.4054651081081644\n",
      "variety : 0.4054651081081644\n",
      "way : 0.4054651081081644\n",
      "depending : 0.4054651081081644\n",
      "machine : 0.0\n",
      "which : 0.4054651081081644\n",
      "understand : 0.006006890490491325\n",
      "analysis : 0.0\n",
      "ambiguity : 0.0030034452452456623\n",
      "wide : 0.0030034452452456623\n",
      "concerned : 0.0030034452452456623\n",
      ") : 0.0\n",
      "with : 0.0\n",
      "techniques : -0.0021309783144576365\n",
      "for : 0.0030034452452456623\n",
      "language : 0.01201378098098265\n",
      "summarization : 0.0030034452452456623\n",
      "artificial : 0.0\n",
      "intelligence : 0.0\n",
      "research : 0.0030034452452456623\n",
      "make : -0.0021309783144576365\n",
      "dealing : 0.0030034452452456623\n",
      "field : 0.0\n",
      "and : -0.017047826515661092\n",
      "advances : 0.0030034452452456623\n",
      "deep : 0.0030034452452456623\n",
      "generate : 0.0030034452452456623\n",
      "computers : 0.009010335735736986\n",
      "Natural : 0.0030034452452456623\n",
      "that : -0.0021309783144576365\n",
      "translation : 0.0030034452452456623\n",
      "accurately : 0.0030034452452456623\n",
      "increasingly : 0.0030034452452456623\n",
      "One : 0.0030034452452456623\n",
      "applications : -0.0021309783144576365\n",
      "is : -0.00639293494337291\n",
      "have : 0.0\n",
      "it : 0.006006890490491325\n",
      "important : 0.0030034452452456623\n",
      ", : -0.019178804830118728\n",
      "improvements : 0.0030034452452456623\n",
      ". : -0.010654891572288182\n",
      "However : 0.0030034452452456623\n",
      "human : 0.0030034452452456623\n",
      "range : 0.0030034452452456623\n",
      "key : 0.0030034452452456623\n",
      "learning : -0.004261956628915273\n",
      "process : 0.0030034452452456623\n",
      "a : -0.00639293494337291\n",
      "enable : 0.0030034452452456623\n",
      "area : 0.0030034452452456623\n",
      "to : -0.008523913257830546\n",
      "recent : 0.0030034452452456623\n",
      "performance : 0.0030034452452456623\n",
      "NLP : 0.01201378098098265\n",
      "used : 0.0030034452452456623\n",
      "can : 0.0\n",
      "aims : 0.0030034452452456623\n",
      "difficult : 0.0030034452452456623\n",
      "interaction : 0.0030034452452456623\n",
      "in : -0.01278586988674582\n",
      "are : 0.0030034452452456623\n",
      "useful : 0.0030034452452456623\n",
      "development : 0.0\n",
      "led : 0.0030034452452456623\n",
      "meaningful : 0.0030034452452456623\n",
      "including : -0.0021309783144576365\n",
      "text : 0.006006890490491325\n",
      "of : -0.010654891572288182\n",
      "humans : 0.0030034452452456623\n",
      "interpret : 0.0030034452452456623\n",
      "extraction : 0.0030034452452456623\n",
      "variability : 0.0030034452452456623\n",
      "It : 0.0\n",
      "both : 0.0030034452452456623\n",
      "natural : 0.006006890490491325\n",
      "information : 0.0030034452452456623\n",
      "significant : 0.0030034452452456623\n",
      "processing : 0.0030034452452456623\n",
      "between : 0.0030034452452456623\n",
      "( : 0.0\n",
      "making : 0.0030034452452456623\n",
      "an : -0.0021309783144576365\n",
      "sentiment : 0.0030034452452456623\n",
      "the : -0.00639293494337291\n",
      "challenges : 0.0030034452452456623\n",
      "way : 0.0030034452452456623\n",
      "machine : 0.0\n",
      "which : 0.0030034452452456623\n",
      "type : 0.003495388863001417\n",
      "algorithms : 0.006990777726002834\n",
      "model : 0.006990777726002834\n",
      "labeled : 0.003495388863001417\n",
      "learning : -0.019840142927709026\n",
      "environment : 0.003495388863001417\n",
      "task : 0.003495388863001417\n",
      "categorized : 0.003495388863001417\n",
      "interact : 0.003495388863001417\n",
      "image : 0.003495388863001417\n",
      "vehicles : 0.003495388863001417\n",
      "that : -0.0049600357319272564\n",
      "training : 0.013981555452005669\n",
      "unlabeled : 0.003495388863001417\n",
      "a : -0.0074400535978908855\n",
      "on : 0.017476944315007088\n",
      "focuses : 0.003495388863001417\n",
      ") : 0.0\n",
      "with : 0.0\n",
      "to : -0.0024800178659636282\n",
      "based : 0.003495388863001417\n",
      "applications : -0.0024800178659636282\n",
      "is : -0.0024800178659636282\n",
      "have : 0.0\n",
      "techniques : -0.0024800178659636282\n",
      "recognition : 0.006990777726002834\n",
      "Supervised : 0.003495388863001417\n",
      "Machine : 0.003495388863001417\n",
      ", : -0.019840142927709026\n",
      "( : 0.0\n",
      "can : 0.0\n",
      "data : 0.0\n",
      "diagnosis : 0.003495388863001417\n",
      "Reinforcement : 0.003495388863001417\n",
      "be : 0.003495388863001417\n",
      "artificial : 0.0\n",
      "autonomous : 0.003495388863001417\n",
      "in : -0.0024800178659636282\n",
      "various : 0.0\n",
      "intelligence : 0.0\n",
      "an : -0.0024800178659636282\n",
      "ML : 0.010486166589004252\n",
      "speech : 0.003495388863001417\n",
      "into : 0.003495388863001417\n",
      "reinforcement : 0.003495388863001417\n",
      "predictions : 0.003495388863001417\n",
      "unsupervised : 0.006990777726002834\n",
      "or : 0.003495388863001417\n",
      ". : -0.012400089329818143\n",
      "feedback : 0.003495388863001417\n",
      "development : 0.0\n",
      "while : 0.003495388863001417\n",
      "make : -0.0024800178659636282\n",
      "including : -0.0024800178659636282\n",
      "supervised : 0.003495388863001417\n",
      "involves : 0.0\n",
      "from : 0.0\n",
      "subset : 0.003495388863001417\n",
      "of : -0.0074400535978908855\n",
      "the : -0.0074400535978908855\n",
      "domains : 0.003495388863001417\n",
      "learn : 0.006990777726002834\n",
      "and : -0.012400089329818143\n",
      "depending : 0.003495388863001417\n",
      "medical : 0.003495388863001417\n",
      "decisions : 0.0\n",
      "mining : 0.004014506020872915\n",
      "statistics : 0.004014506020872915\n",
      "e-commerce : 0.004014506020872915\n",
      "data-driven : 0.004014506020872915\n",
      "interdisciplinary : 0.004014506020872915\n",
      "tools : 0.004014506020872915\n",
      "machine : 0.0\n",
      "use : 0.004014506020872915\n",
      "learning : -0.002848337351007732\n",
      "analysis : 0.0\n",
      "has : 0.004014506020872915\n",
      "decisions : 0.0\n",
      "that : -0.002848337351007732\n",
      "Data : 0.012043518062618743\n",
      "uncover : 0.004014506020872915\n",
      "a : -0.002848337351007732\n",
      "patterns : 0.004014506020872915\n",
      "trends : 0.004014506020872915\n",
      "collection : 0.004014506020872915\n",
      "to : -0.005696674702015464\n",
      "marketing : 0.004014506020872915\n",
      "applications : -0.002848337351007732\n",
      "is : -0.002848337351007732\n",
      "cleaning : 0.004014506020872915\n",
      "techniques : -0.005696674702015464\n",
      ", : -0.039876722914108244\n",
      "extract : 0.004014506020872915\n",
      "data : 0.0\n",
      "industries : 0.004014506020872915\n",
      "as : 0.004014506020872915\n",
      "statistical : 0.004014506020872915\n",
      "in : -0.005696674702015464\n",
      "various : 0.0\n",
      "an : -0.002848337351007732\n",
      "knowledge : 0.00802901204174583\n",
      "insights : 0.004014506020872915\n",
      "computer : 0.004014506020872915\n",
      "numerous : 0.004014506020872915\n",
      "stages : 0.004014506020872915\n",
      "modeling : 0.004014506020872915\n",
      ". : -0.011393349404030927\n",
      "scientists : 0.004014506020872915\n",
      "such : 0.004014506020872915\n",
      "make : -0.002848337351007732\n",
      "finance : 0.004014506020872915\n",
      "including : -0.005696674702015464\n",
      "visualization : 0.004014506020872915\n",
      "involves : 0.0\n",
      "from : 0.0\n",
      "healthcare : 0.004014506020872915\n",
      "science : 0.012043518062618743\n",
      "combines : 0.004014506020872915\n",
      "of : -0.005696674702015464\n",
      "the : -0.002848337351007732\n",
      "domain-specific : 0.004014506020872915\n",
      "variety : 0.004014506020872915\n",
      "field : 0.0\n",
      "and : -0.022786698808061855\n",
      "lifecycle : 0.004014506020872915\n",
      "It : 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_tf(docs):\n",
    "    tf = {}\n",
    "    for doc in docs:\n",
    "        tokens = word_tokenize(doc)\n",
    "        total_terms = len(tokens)\n",
    "        for token in set(tokens):\n",
    "            frequency = tokens.count(token)\n",
    "            tf[(token, doc)] = frequency/total_terms\n",
    "    return tf\n",
    "\n",
    "def get_idf(docs):\n",
    "    idf = {}\n",
    "    tokens = []\n",
    "    for doc in docs:\n",
    "        tokens += word_tokenize(doc)\n",
    "    for token in set(tokens):\n",
    "        count = 1\n",
    "        for d in docs:\n",
    "            if token in word_tokenize(d):\n",
    "                count += 1\n",
    "        idf[token] = math.log(len(docs)/count)\n",
    "    return idf\n",
    "\n",
    "def get_tfidf(docs):\n",
    "    tf = get_tf(docs)\n",
    "    idf = get_idf(docs)\n",
    "    tfidf = {}\n",
    "    for token, doc in tf.keys():\n",
    "        tfidf[(token, doc)] = tf[(token, doc)] * idf[token]\n",
    "    return tfidf\n",
    "\n",
    "doc1 = \"Natural language processing (NLP) is a field of artificial intelligence concerned with the interaction between computers and humans in natural language. It aims to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP techniques are used in a wide range of applications, including machine translation, sentiment analysis, information extraction, and text summarization. One of the key challenges in NLP is dealing with the ambiguity and variability of natural language, which can make it difficult for computers to accurately process and understand text. However, recent advances in machine learning and deep learning have led to significant improvements in NLP performance, making it an increasingly important area of research and development.\"\n",
    "doc2 = \"Machine learning (ML) is a subset of artificial intelligence that focuses on the development of algorithms that can learn from and make predictions or decisions based on data. ML algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning, depending on the type of training data and the learning task. Supervised learning involves training a model on labeled data, while unsupervised learning involves training on unlabeled data. Reinforcement learning involves training a model to interact with an environment and learn from feedback. ML techniques have applications in various domains, including image recognition, speech recognition, medical diagnosis, and autonomous vehicles.\"\n",
    "doc3 = \"Data science is an interdisciplinary field that combines techniques from statistics, computer science, and domain-specific knowledge to extract insights and knowledge from data. It involves various stages of the data lifecycle, including data collection, data cleaning, data analysis, and data visualization. Data scientists use a variety of tools and techniques, such as machine learning, statistical modeling, and data mining, to uncover patterns and trends in data and make data-driven decisions. Data science has applications in numerous industries, including healthcare, finance, marketing, and e-commerce.\"\n",
    "\n",
    "tf = get_tf([doc1, doc2, doc3])\n",
    "idf = get_idf([doc1, doc2, doc3])\n",
    "tfidf = get_tfidf([doc1, doc2, doc3])\n",
    "\n",
    "for token, doc in tf.keys():\n",
    "    print(token, \":\", tf[(token, doc)])\n",
    "\n",
    "for token in idf.keys():\n",
    "    print(token, \":\", idf[token])\n",
    "\n",
    "for token, doc in tfidf.keys():\n",
    "    print(token, \":\", tfidf[(token, doc)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
